{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import pandas as pd\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Feature Selection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we know which classifier we want to use, it is time to take a closer look at the features.\n",
      "\n",
      "We will combine our four feature groups in different ways. If one or more feature groups are non-informative or redundant, we should notice.\n",
      "\n",
      "First we divide our features into their corresponding groups:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_morf = np.load(\"../data/y_morf.npy\")\n",
      "X_myfeat_morf = np.load(\"../data/X_myfeat_morf.npy\")\n",
      "X_myfeat_morf_ps = X_myfeat_morf[:,:300]\n",
      "X_myfeat_morf_aa = X_myfeat_morf[:,300:320]\n",
      "X_myfeat_morf_do = X_myfeat_morf[:,320:324]\n",
      "X_myfeat_morf_ss = X_myfeat_morf[:,324:327]\n",
      "\n",
      "y_pros = np.load(\"../data/y_pros.npy\")\n",
      "X_myfeat_pros = np.load(\"../data/X_myfeat_pros.npy\")\n",
      "X_myfeat_pros_ps = X_myfeat_pros[:,:300]\n",
      "X_myfeat_pros_aa = X_myfeat_pros[:,300:320]\n",
      "X_myfeat_pros_do = X_myfeat_pros[:,320:324]\n",
      "X_myfeat_pros_ss = X_myfeat_pros[:,324:327]\n",
      "\n",
      "y_both = np.load(\"../data/y_both.npy\")\n",
      "X_myfeat_both = np.load(\"../data/X_myfeat_both.npy\")\n",
      "X_myfeat_both_ps = X_myfeat_both[:,:300]\n",
      "X_myfeat_both_aa = X_myfeat_both[:,300:320]\n",
      "X_myfeat_both_do = X_myfeat_both[:,320:324]\n",
      "X_myfeat_both_ss = X_myfeat_both[:,324:327]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As from now on, we will stick to the Extra Trees classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import make_scorer\n",
      "from sklearn.metrics import matthews_corrcoef\n",
      "mcc = make_scorer(matthews_corrcoef)\n",
      "\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "cv_morf = StratifiedKFold(y_morf, n_folds=5,\n",
      "                          shuffle=True, random_state=42)\n",
      "cv_pros = StratifiedKFold(y_pros, n_folds=5,\n",
      "                          shuffle=True, random_state=42)\n",
      "cv_both = StratifiedKFold(y_both, n_folds=5,\n",
      "                          shuffle=True, random_state=42)\n",
      "\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "et_clf = make_pipeline(StandardScaler(),\n",
      "                       ExtraTreesClassifier(n_estimators=50,\n",
      "                                            class_weight=\"auto\",\n",
      "                                            random_state=42))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We put the feature groups into a dictionary for easier access."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_myfeat_morf_dict = {\"ps\": X_myfeat_morf_ps, \"aa\": X_myfeat_morf_aa,\n",
      "                      \"do\": X_myfeat_morf_do, \"ss\": X_myfeat_morf_ss}\n",
      "\n",
      "X_myfeat_pros_dict = {\"ps\": X_myfeat_pros_ps, \"aa\": X_myfeat_pros_aa,\n",
      "                      \"do\": X_myfeat_pros_do, \"ss\": X_myfeat_pros_ss}\n",
      "\n",
      "X_myfeat_both_dict = {\"ps\": X_myfeat_both_ps, \"aa\": X_myfeat_both_aa,\n",
      "                      \"do\": X_myfeat_both_do, \"ss\": X_myfeat_both_ss}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "from itertools import chain, combinations\n",
      "def all_subsets(ss):\n",
      "  return chain(*map(lambda x: combinations(ss, x), range(1, len(ss)+1)))\n",
      "\n",
      "feature_tags = [\"ps\", \"aa\", \"do\", \"ss\"]\n",
      "tags = []\n",
      "\n",
      "morf_features_scores = {}\n",
      "pros_features_scores = {}\n",
      "both_features_scores = {}\n",
      "\n",
      "for subset in all_subsets(feature_tags):\n",
      "    tag = \"_\".join(list(subset))\n",
      "    tags.append(tag)\n",
      "    \n",
      "    morf_features = np.zeros((X_myfeat_morf_dict[\"ps\"].shape[0], 1))\n",
      "    pros_features = np.zeros((X_myfeat_pros_dict[\"ps\"].shape[0], 1))\n",
      "    both_features = np.zeros((X_myfeat_both_dict[\"ps\"].shape[0], 1))\n",
      "    \n",
      "    for feat_set in subset:\n",
      "        morf_features = np.hstack((morf_features, X_myfeat_morf_dict[feat_set]))\n",
      "        pros_features = np.hstack((pros_features, X_myfeat_pros_dict[feat_set]))\n",
      "        both_features = np.hstack((both_features, X_myfeat_both_dict[feat_set]))\n",
      "        \n",
      "    morf_features = morf_features[:,1:]\n",
      "    pros_features = pros_features[:,1:]\n",
      "    both_features = both_features[:,1:]\n",
      "    \n",
      "    morf_features_scores[tag] = cross_val_score(et_clf, morf_features, y_morf,\n",
      "                                                scoring=mcc, cv=cv_morf, n_jobs=5)\n",
      "    pros_features_scores[tag] = cross_val_score(et_clf, pros_features, y_pros,\n",
      "                                                scoring=mcc, cv=cv_pros, n_jobs=5)\n",
      "    both_features_scores[tag] = cross_val_score(et_clf, both_features, y_both,\n",
      "                                                scoring=mcc, cv=cv_both, n_jobs=3)\n",
      "%store morf_features_scores\n",
      "%store pros_features_scores\n",
      "%store both_features_scores\n",
      "%store tags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_myfeat_pros_ss"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[ 0.995,  0.001,  0.005],\n",
        "       [ 0.789,  0.045,  0.113],\n",
        "       [ 0.786,  0.044,  0.121],\n",
        "       ..., \n",
        "       [ 0.434,  0.12 ,  0.357],\n",
        "       [ 0.593,  0.048,  0.333],\n",
        "       [ 0.997,  0.002,  0.002]])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_data = {\"mcc_score\": np.zeros((1,)),\n",
      "                \"dataset\": [],\n",
      "                \"features\": []}\n",
      "\n",
      "for tag in tags:\n",
      "    feature_data[\"mcc_score\"] = np.hstack((feature_data[\"mcc_score\"], morf_features_scores[tag]))\n",
      "    feature_data[\"dataset\"] = feature_data[\"dataset\"] + [\"MoRF\"] * 5\n",
      "    feature_data[\"features\"] = feature_data[\"features\"] + [tag] * 5\n",
      "    \n",
      "    feature_data[\"mcc_score\"] = np.hstack((feature_data[\"mcc_score\"], pros_features_scores[tag]))\n",
      "    feature_data[\"dataset\"] = feature_data[\"dataset\"] + [\"ProS\"] * 5\n",
      "    feature_data[\"features\"] = feature_data[\"features\"] + [tag] * 5\n",
      "    \n",
      "    feature_data[\"mcc_score\"] = np.hstack((feature_data[\"mcc_score\"], both_features_scores[tag]))\n",
      "    feature_data[\"dataset\"] = feature_data[\"dataset\"] + [\"Both\"] * 5\n",
      "    feature_data[\"features\"] = feature_data[\"features\"] + [tag] * 5\n",
      "    \n",
      "feature_data[\"mcc_score\"] = feature_data[\"mcc_score\"][1:]\n",
      "\n",
      "feature_data = pd.DataFrame(feature_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'ss'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-8-0b7d51ba1961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfeature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfeature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mcc_score\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mcc_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboth_features_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mfeature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Both\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfeature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyError\u001b[0m: 'ss'"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sns.factorplot(\"dataset\", \"mcc_score\", \"features\",\n",
      "               feature_data, kind=\"bar\", aspect=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "unhashable type: 'list'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-7-c5eba2b841f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sns.factorplot(\"dataset\", \"mcc_score\", \"features\",\n\u001b[0;32m----> 2\u001b[0;31m                feature_data, kind=\"bar\", aspect=3)\n\u001b[0m",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/seaborn/linearmodels.pyc\u001b[0m in \u001b[0;36mfactorplot\u001b[0;34m(x, y, hue, data, row, col, col_wrap, estimator, ci, n_boot, units, x_order, hue_order, col_order, row_order, kind, markers, linestyles, dodge, join, hline, size, aspect, palette, legend, legend_out, dropna, sharex, sharey, margin_titles)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0mfacet_hue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del1 = np.linspace(1, 30, 12, endpoint=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "del2 = np.logspace(np.log2(30), np.log2(200), 8, base=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alla = np.hstack((del1, del2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alla.astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "array([  1,   3,   5,   8,  10,  13,  15,  17,  20,  22,  25,  27,  30,\n",
        "        39,  51,  67,  88, 116, 152, 199])"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}